{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 8977525,
          "sourceType": "datasetVersion",
          "datasetId": 5405420
        }
      ],
      "dockerImageVersionId": 31193,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "notebook8fe32a963d",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "bertvankeulen_cicids_2017_path = kagglehub.dataset_download('bertvankeulen/cicids-2017')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "occUTxQCXW3c"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-09T16:25:54.201702Z",
          "iopub.execute_input": "2025-12-09T16:25:54.202399Z",
          "iopub.status.idle": "2025-12-09T16:25:54.486655Z",
          "shell.execute_reply.started": "2025-12-09T16:25:54.202374Z",
          "shell.execute_reply": "2025-12-09T16:25:54.485977Z"
        },
        "id": "oXBzX6fZXW3e",
        "outputId": "658ebe2e-a006-4109-9dcb-878b416fde28"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "/kaggle/input/cicids-2017/wednesday_plus.csv\n/kaggle/input/cicids-2017/thursday_plus.csv\n/kaggle/input/cicids-2017/friday_plus.csv\n/kaggle/input/cicids-2017/tuesday.csv\n/kaggle/input/cicids-2017/monday.csv\n/kaggle/input/cicids-2017/friday.csv\n/kaggle/input/cicids-2017/wednesday.csv\n/kaggle/input/cicids-2017/thursday.csv\n/kaggle/input/cicids-2017/tuesday_plus.csv\n/kaggle/input/cicids-2017/monday_plus.csv\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Multi-Class IDS with Automatic Feature Selection\n",
        "# Models: DecisionTree, RandomForest, XGBoost\n",
        "# ================================\n",
        "\n",
        "import os\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, classification_report, roc_auc_score,\n",
        "    confusion_matrix\n",
        ")\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import LabelEncoder, label_binarize"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-09T16:33:27.096449Z",
          "iopub.execute_input": "2025-12-09T16:33:27.097056Z",
          "iopub.status.idle": "2025-12-09T16:33:27.452198Z",
          "shell.execute_reply.started": "2025-12-09T16:33:27.097027Z",
          "shell.execute_reply": "2025-12-09T16:33:27.451343Z"
        },
        "id": "WLmeQNtUXW3f"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = Path(\"/kaggle/input/cicids-2017\")\n",
        "\n",
        "csv_files = sorted(DATA_DIR.glob(\"*.csv\"))\n",
        "if not csv_files:\n",
        "    raise FileNotFoundError(f\"No CSV files found in {DATA_DIR}\")\n",
        "\n",
        "df_list = []\n",
        "for f in csv_files:\n",
        "    print(\"Loading:\", f.name)\n",
        "    df_part = pd.read_csv(f)\n",
        "    df_list.append(df_part)\n",
        "\n",
        "# Merge all parts\n",
        "df = pd.concat(df_list, ignore_index=True)\n",
        "print(\"Loaded shape:\", df.shape)\n",
        "\n",
        "merged_path = \"cicids2017_merged.csv\"\n",
        "df.to_csv(merged_path, index=False)\n",
        "print(f\"Merged dataset saved to {merged_path}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-09T16:33:35.22224Z",
          "iopub.execute_input": "2025-12-09T16:33:35.222512Z",
          "iopub.status.idle": "2025-12-09T16:37:20.208888Z",
          "shell.execute_reply.started": "2025-12-09T16:33:35.222491Z",
          "shell.execute_reply": "2025-12-09T16:37:20.208109Z"
        },
        "id": "0W_5DfYKXW3g",
        "outputId": "5f6b2edc-a984-4484-e4a9-9e3202958a72"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Loading: friday.csv\nLoading: friday_plus.csv\nLoading: monday.csv\nLoading: monday_plus.csv\nLoading: thursday.csv\nLoading: thursday_plus.csv\nLoading: tuesday.csv\nLoading: tuesday_plus.csv\nLoading: wednesday.csv\nLoading: wednesday_plus.csv\nLoaded shape: (4199942, 105)\nMerged dataset saved to cicids2017_merged.csv\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 2. Preprocessing\n",
        "# ================================\n",
        "df = df.dropna()\n",
        "print(\"After dropna:\", df.shape)\n",
        "\n",
        "y = df[\"Label\"]\n",
        "X = df.drop(columns=[\"Label\"])\n",
        "\n",
        "# ðŸ”Ž Keep only numeric features\n",
        "X = X.select_dtypes(include=[np.number])\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "class_names = label_encoder.classes_\n",
        "print(\"Classes:\", class_names)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")\n",
        "\n",
        "print(\"Feature matrix shape:\", X.shape)\n",
        "print(\"Train/Test split:\", X_train.shape, X_test.shape)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-09T16:37:20.210155Z",
          "iopub.execute_input": "2025-12-09T16:37:20.210467Z",
          "iopub.status.idle": "2025-12-09T16:37:27.682545Z",
          "shell.execute_reply.started": "2025-12-09T16:37:20.210448Z",
          "shell.execute_reply": "2025-12-09T16:37:27.681903Z"
        },
        "id": "bvAGTPXoXW3g",
        "outputId": "cec19ca6-b4a7-4f15-e429-4d18dab3843c"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "After dropna: (2099971, 105)\nClasses: ['BENIGN' 'Botnet' 'Botnet - Attempted' 'DDoS' 'DoS GoldenEye'\n 'DoS GoldenEye - Attempted' 'DoS Hulk' 'DoS Hulk - Attempted'\n 'DoS Slowhttptest' 'DoS Slowhttptest - Attempted' 'DoS Slowloris'\n 'DoS Slowloris - Attempted' 'FTP-Patator' 'FTP-Patator - Attempted'\n 'Heartbleed' 'Infiltration' 'Infiltration - Attempted'\n 'Infiltration - Portscan' 'Portscan' 'SSH-Patator'\n 'SSH-Patator - Attempted' 'Web Attack - Brute Force'\n 'Web Attack - Brute Force - Attempted' 'Web Attack - SQL Injection'\n 'Web Attack - SQL Injection - Attempted' 'Web Attack - XSS'\n 'Web Attack - XSS - Attempted']\nFeature matrix shape: (2099971, 102)\nTrain/Test split: (1679976, 102) (419995, 102)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 3. Helper Functions\n",
        "# ================================\n",
        "def evaluate_model(name, model, X_test, y_test, label_encoder):\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print(f\"--- {name} ---\")\n",
        "    print(\"Accuracy:\", acc)\n",
        "    print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "    # ROC AUC for multiclass\n",
        "    try:\n",
        "        y_score = model.predict_proba(X_test)\n",
        "        y_bin = label_binarize(y_test, classes=np.arange(len(label_encoder.classes_)))\n",
        "        auc = roc_auc_score(y_bin, y_score, average=\"macro\", multi_class=\"ovr\")\n",
        "    except Exception:\n",
        "        auc = None\n",
        "    print(\"ROC AUC:\", auc)\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print(\"Confusion matrix:\\n\", cm)\n",
        "\n",
        "    #  TP, TN, FP, FN (for binary classes only)\n",
        "    if len(label_encoder.classes_) == 2:\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "        print(f\" True Positive (TP): {tp}\")\n",
        "        print(f\" False Positive (FP): {fp}\")\n",
        "        print(f\" False Negative (FN): {fn}\")\n",
        "        print(f\" True Negative (TN): {tn}\")\n",
        "\n",
        "    #  Percentage Analyzer\n",
        "    per_class_stats = {}\n",
        "    for i, cls in enumerate(label_encoder.classes_):\n",
        "        correct = cm[i, i]\n",
        "        total = cm[i, :].sum()\n",
        "        acc_cls = correct / total if total > 0 else 0\n",
        "        mis = 1 - acc_cls\n",
        "        print(f\"ðŸ“Š {cls}: {correct}/{total} correct = {acc_cls*100:.2f}% | Misclassified = {mis*100:.2f}%\")\n",
        "        per_class_stats[cls] = acc_cls * 100\n",
        "\n",
        "    return {\n",
        "        \"Model\": name,\n",
        "        \"Accuracy\": acc,\n",
        "        \"ROC_AUC\": auc,\n",
        "        **{f\"{cls} Correct %\": v for cls, v in per_class_stats.items()}\n",
        "    }\n",
        "\n",
        "def extract_features(model, X_train, name, top_k=15):\n",
        "    \"\"\"Extract feature importance for tree-based models\"\"\"\n",
        "    if hasattr(model, \"feature_importances_\"):\n",
        "        importances = model.feature_importances_\n",
        "        feat_df = pd.DataFrame({\n",
        "            \"Feature\": X_train.columns,\n",
        "            f\"{name}_Importance\": importances\n",
        "        }).sort_values(by=f\"{name}_Importance\", ascending=False).head(top_k)\n",
        "        return feat_df\n",
        "    else:\n",
        "        return pd.DataFrame(columns=[\"Feature\", f\"{name}_Importance\"])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-09T16:37:27.683332Z",
          "iopub.execute_input": "2025-12-09T16:37:27.683565Z",
          "iopub.status.idle": "2025-12-09T16:37:27.692146Z",
          "shell.execute_reply.started": "2025-12-09T16:37:27.683548Z",
          "shell.execute_reply": "2025-12-09T16:37:27.691561Z"
        },
        "id": "o3GMSSgTXW3h"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        " # ================================\n",
        "# 4. Feature Selection\n",
        "# ================================\n",
        "print(\"\\n Running feature selection...\")\n",
        "fs_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "fs_model.fit(X_train, y_train)\n",
        "\n",
        "feat_importances = pd.DataFrame({\n",
        "    \"Feature\": X_train.columns,\n",
        "    \"Importance\": fs_model.feature_importances_\n",
        "}).sort_values(by=\"Importance\", ascending=False)\n",
        "\n",
        "TOP_K = 30\n",
        "top_features = feat_importances.head(TOP_K)[\"Feature\"].tolist()\n",
        "print(f\"Selected top {TOP_K} features:\", top_features)\n",
        "\n",
        "# Reduce datasets\n",
        "X_train = X_train[top_features]\n",
        "X_test = X_test[top_features]\n",
        "\n",
        "feat_importances.to_csv(\"all_feature_importances.csv\", index=False)\n",
        "pd.DataFrame(top_features, columns=[\"TopFeatures\"]).to_csv(\"selected_features.csv\", index=False)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-09T16:37:43.167255Z",
          "iopub.execute_input": "2025-12-09T16:37:43.167706Z"
        },
        "id": "RSBDdaOAXW3h",
        "outputId": "c7c0c9ff-2b9b-4d10-9fdb-1025f5299482"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\n Running feature selection...\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 5. Train Models on Selected Features\n",
        "# ================================\n",
        "results = []\n",
        "feature_dfs = []\n",
        "\n",
        "# Decision Tree\n",
        "dt = DecisionTreeClassifier(max_depth=20, random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "results.append(evaluate_model(\"Decision Tree\", dt, X_test, y_test, label_encoder))\n",
        "feature_dfs.append(extract_features(dt, X_train, \"DecisionTree\"))\n",
        "joblib.dump(dt, \"decision_tree.pkl\")\n",
        "\n",
        "# Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=150, max_depth=25, random_state=42, n_jobs=-1)\n",
        "rf.fit(X_train, y_train)\n",
        "results.append(evaluate_model(\"Random Forest\", rf, X_test, y_test, label_encoder))\n",
        "feature_dfs.append(extract_features(rf, X_train, \"RandomForest\"))\n",
        "joblib.dump(rf, \"random_forest.pkl\")\n",
        "\n",
        "# XGBoost\n",
        "xgb_clf = XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=10,\n",
        "    learning_rate=0.1,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    eval_metric=\"mlogloss\",\n",
        "    use_label_encoder=False,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "xgb_clf.fit(X_train, y_train)\n",
        "results.append(evaluate_model(\"XGBoost\", xgb_clf, X_test, y_test, label_encoder))\n",
        "feature_dfs.append(extract_features(xgb_clf, X_train, \"XGBoost\"))\n",
        "joblib.dump(xgb_clf, \"xgboost.pkl\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "_92jH-BKXW3i"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 6. Save Results\n",
        "# ================================\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_csv(\"model_results.csv\", index=False)\n",
        "print(\"\\nðŸ“‚ Results saved to model_results.csv\")\n",
        "print(results_df)"
      ],
      "metadata": {
        "trusted": true,
        "id": "WwVE2xT1XW3j"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 7. Plot Feature Importances\n",
        "# ================================\n",
        "feat_all = feature_dfs[0]\n",
        "for df_tmp in feature_dfs[1:]:\n",
        "    feat_all = feat_all.merge(df_tmp, on=\"Feature\", how=\"outer\")\n",
        "\n",
        "feat_all.fillna(0, inplace=True)\n",
        "feat_all.to_csv(\"feature_importances_selected.csv\", index=False)\n",
        "\n",
        "plt.figure(figsize=(14, 8))\n",
        "for col in feat_all.columns[1:]:\n",
        "    sns.barplot(x=\"Feature\", y=col, data=feat_all.head(10), label=col)\n",
        "plt.xticks(rotation=90)\n",
        "plt.title(\"Top Features (Selected Set)\")\n",
        "plt.ylabel(\"Importance Score\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "kxGTKAhcXW3j"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}